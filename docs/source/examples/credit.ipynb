{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# German Credit Risk - Bias\n",
    "This notebook computes the gender bias of models developed on the *German Credit Risk* dataset.\n",
    "\n",
    "__Source__: [https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from fairscoring.metrics import bias_pe, bias_eo, bias_cal, WassersteinMetric, CalibrationMetric\n",
    "from fairscoring.metrics.roc import bias_roc, bias_xroc\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Load and pre-process data\n",
    "### Load German Credit Risk data from [OpenML](https://api.openml.org/d/46116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "openML_ID = 46116\n",
    "data = fetch_openml(data_id=openML_ID)\n",
    "features = data.data.copy()\n",
    "target = data.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Drop index Column\n",
    "# features.drop(\"Unnamed:_0\", axis=1, inplace=True)\n",
    "\n",
    "# Fill n/a\n",
    "features['Saving accounts'] = features['Saving accounts'].astype(object).fillna('no_inf')\n",
    "features['Checking account'] = features['Checking account'].astype(object).fillna('no_inf')\n",
    "\n",
    "# Small beautification\n",
    "features['Purpose'] = features['Purpose'].replace(\"'domestic appliances'\", \"domestic appliances\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_columns = ['Credit amount', 'Duration']\n",
    "cat_columns = ['Job', 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ordinal_enc = OrdinalEncoder().fit(features[cat_columns])\n",
    "features[cat_columns]=ordinal_enc.transform(features[cat_columns])\n",
    "features[cat_columns]=features[cat_columns].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "categorical = pd.get_dummies(features[cat_columns].astype(str), drop_first=True)\n",
    "numerical = MinMaxScaler().fit_transform(features[num_columns])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "target_encoder = LabelEncoder()\n",
    "target= target_encoder.fit_transform(target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training\n",
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "log_reg_data=pd.concat([pd.DataFrame(categorical), pd.DataFrame(numerical)], axis=1)\n",
    "log_reg_data=log_reg_data.rename(columns = {0:'Credit amount', 1:'Duration'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(log_reg_data.astype(float), target.astype(int), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Train LogReg Model\n",
    "#### Cross-Validation to check for stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC values for 5-fold Cross Validation:\n",
      " [0.62074468 0.76400111 0.78967544 0.75111461 0.71436404]\n",
      "\n",
      "Standard Deviation of ROC AUC of the models: 0.059\n",
      "\n",
      "Final Average ROC AUC of the model: 0.728\n"
     ]
    }
   ],
   "source": [
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=2579)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "ROC_Values=cross_val_score(logreg, X_train , y_train, cv=shuffle, scoring=\"roc_auc\")\n",
    "\n",
    "print('\\nROC AUC values for 5-fold Cross Validation:\\n',ROC_Values)\n",
    "print('\\nStandard Deviation of ROC AUC of the models:', round(ROC_Values.std(),3))\n",
    "print('\\nFinal Average ROC AUC of the model:', round(ROC_Values.mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506663\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logreg = sm.Logit(y_train, X_train).fit()\n",
    "# performing predictions on the test datdaset\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "prediction_test = list(map(round, y_pred))\n",
    "prediction_train = list(map(round, y_pred_train))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Train debiased LogReg Model\n",
    "#### Remove Gender Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_wosex = X_train.drop(X_train.columns[[19,19]], axis=1)\n",
    "X_test_wosex = X_test.drop(X_train.columns[[19,19]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Cross-Validation to check for stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC values for 5-fold Cross Validation:\n",
      " [0.6087766  0.77904709 0.78507539 0.73826383 0.71299342]\n",
      "\n",
      "Standard Deviation of ROC AUC of the models: 0.064\n",
      "\n",
      "Final Average ROC AUC of the model: 0.725\n"
     ]
    }
   ],
   "source": [
    "shuffle = KFold(n_splits=5, shuffle=True, random_state=2579)\n",
    "logreg_wosex = LogisticRegression(max_iter=1000)\n",
    "ROC_Values=cross_val_score(logreg_wosex, X_train_wosex, y_train, cv=shuffle, scoring=\"roc_auc\")\n",
    "\n",
    "print('\\nROC AUC values for 5-fold Cross Validation:\\n',ROC_Values)\n",
    "print('\\nStandard Deviation of ROC AUC of the models:', round(ROC_Values.std(),3))\n",
    "print('\\nFinal Average ROC AUC of the model:', round(ROC_Values.mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.510914\n",
      "         Iterations 6\n",
      "The ROC-AUC of the Logistic Regression is 0.7712395693717844\n",
      "The train-ROC-AUC of the Logistic Regression is 0.765014029809344\n"
     ]
    }
   ],
   "source": [
    "logreg_wosex = sm.Logit(y_train, X_train_wosex).fit()\n",
    "\n",
    "y_pred_wosex = logreg_wosex.predict(X_test_wosex)\n",
    "y_pred_train_wosex = logreg_wosex.predict(X_train_wosex)\n",
    "\n",
    "roc_score_logreg_wosex = roc_auc_score(y_test, y_pred_wosex)\n",
    "roc_score_logreg_wosex_train = roc_auc_score(y_train, y_pred_train_wosex)\n",
    "\n",
    "print('The ROC-AUC of the Logistic Regression is', roc_score_logreg_wosex)\n",
    "print('The train-ROC-AUC of the Logistic Regression is', roc_score_logreg_wosex_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Bias Measures\n",
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "attribute = data.data.loc[X_test.index,\"Sex\"]\n",
    "\n",
    "groups = ['female', 'male']\n",
    "\n",
    "favorable_target = target_encoder.transform([\"good\"])[0]\n",
    "\n",
    "models = [\n",
    "    (\"LogReg\", y_pred),\n",
    "    (\"LogReg (debiased)\", y_pred_wosex),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### List of bias metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    bias_eo,     # Standardized Equal Opportunity\n",
    "    bias_pe,     # Standardized Predictive Equality\n",
    "    bias_cal,    # Standardized Calibration Equality\n",
    "    bias_roc,    # ROC-Bias\n",
    "    bias_xroc,   # xROC-Bias\n",
    "    WassersteinMetric(fairness_type=\"EO\",name=\"Equal Opportunity (U)\", score_transform=\"rescale\"),\n",
    "    WassersteinMetric(fairness_type=\"PE\",name=\"Predictive Equality (U)\", score_transform=\"rescale\"),\n",
    "    CalibrationMetric(weighting=\"scores\",name=\"Calibration (U)\", score_transform=\"rescale\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Compute Bias Metrics\n",
    "Compute all bias metrics for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be073427afc84faea1a50a2f869c52fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  fraction_of_positives = np.where(nonzero, bin_true / bin_total, np.nan)\n",
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  mean_predicted_value = np.where(nonzero, bin_sums / bin_total, np.nan)\n",
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  fraction_of_positives = np.where(nonzero, bin_true / bin_total, np.nan)\n",
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  mean_predicted_value = np.where(nonzero, bin_sums / bin_total, np.nan)\n",
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  fraction_of_positives = np.where(nonzero, bin_true / bin_total, np.nan)\n",
      "C:\\dev\\fair-scoring-public\\src\\fairscoring\\metrics\\_calibration.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  mean_predicted_value = np.where(nonzero, bin_sums / bin_total, np.nan)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for metric in tqdm(metrics):\n",
    "    for model, scores in models:\n",
    "        # Compute bias\n",
    "        bias = metric.bias(\n",
    "            scores, y_test, attribute,\n",
    "            groups=groups,\n",
    "            favorable_target=favorable_target,\n",
    "            min_score=0, max_score=1,\n",
    "            n_permute=1000, seed=2579)\n",
    "\n",
    "        # Store result\n",
    "        results.append((metric, model, bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Result Table I\n",
    "_Models vertically arranged_\n",
    "This corresponds to table C2 in the publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           total  pos   neg p-value\nmetric                  model                                      \nEqual Opportunity       LogReg             0.083   1%   99%    0.04\n                        LogReg (debiased)  0.048  93%    7%    0.32\nPredictive Equality     LogReg             0.092   0%  100%    0.09\n                        LogReg (debiased)  0.025  62%   38%    0.99\nCalibration             LogReg             0.291  46%   54%    0.35\n                        LogReg (debiased)  0.299  58%   42%    0.26\nROC bias                LogReg             0.044  98%    2%    0.80\n                        LogReg (debiased)  0.050  98%    2%    0.69\nxROC bias               LogReg             0.133   0%  100%    0.02\n                        LogReg (debiased)  0.057  93%    7%    0.54\nEqual Opportunity (U)   LogReg             0.041   3%   97%    0.13\n                        LogReg (debiased)  0.036  97%    3%    0.23\nPredictive Equality (U) LogReg             0.078   1%   99%    0.10\n                        LogReg (debiased)  0.024  74%   26%    0.98\nCalibration (U)         LogReg             0.246  40%   60%    0.57\n                        LogReg (debiased)  0.225  75%   25%    0.84",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>total</th>\n      <th>pos</th>\n      <th>neg</th>\n      <th>p-value</th>\n    </tr>\n    <tr>\n      <th>metric</th>\n      <th>model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Equal Opportunity</th>\n      <th>LogReg</th>\n      <td>0.083</td>\n      <td>1%</td>\n      <td>99%</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.048</td>\n      <td>93%</td>\n      <td>7%</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Predictive Equality</th>\n      <th>LogReg</th>\n      <td>0.092</td>\n      <td>0%</td>\n      <td>100%</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.025</td>\n      <td>62%</td>\n      <td>38%</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Calibration</th>\n      <th>LogReg</th>\n      <td>0.291</td>\n      <td>46%</td>\n      <td>54%</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.299</td>\n      <td>58%</td>\n      <td>42%</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ROC bias</th>\n      <th>LogReg</th>\n      <td>0.044</td>\n      <td>98%</td>\n      <td>2%</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.050</td>\n      <td>98%</td>\n      <td>2%</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">xROC bias</th>\n      <th>LogReg</th>\n      <td>0.133</td>\n      <td>0%</td>\n      <td>100%</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.057</td>\n      <td>93%</td>\n      <td>7%</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Equal Opportunity (U)</th>\n      <th>LogReg</th>\n      <td>0.041</td>\n      <td>3%</td>\n      <td>97%</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.036</td>\n      <td>97%</td>\n      <td>3%</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Predictive Equality (U)</th>\n      <th>LogReg</th>\n      <td>0.078</td>\n      <td>1%</td>\n      <td>99%</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.024</td>\n      <td>74%</td>\n      <td>26%</td>\n      <td>0.98</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Calibration (U)</th>\n      <th>LogReg</th>\n      <td>0.246</td>\n      <td>40%</td>\n      <td>60%</td>\n      <td>0.57</td>\n    </tr>\n    <tr>\n      <th>LogReg (debiased)</th>\n      <td>0.225</td>\n      <td>75%</td>\n      <td>25%</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [[\n",
    "    metric.name,\n",
    "    model,\n",
    "    f\"{bias.bias:.3f}\",\n",
    "    f\"{100*bias.pos_component:.0f}%\",\n",
    "    f\"{100*bias.neg_component:.0f}%\",\n",
    "    f\"{bias.p_value:.2f}\" ] for metric, model, bias in results\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"metric\", \"model\", \"total\", \"pos\", \"neg\", \"p-value\"])\n",
    "df.set_index([\"metric\", \"model\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Table II\n",
    "_Models horizontally arranged_\n",
    "This corresponds to table 2 in the publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_names = [name for name, _ in models]\n",
    "\n",
    "blocks = [df[df.index.get_level_values(1) == name] for name in model_names]\n",
    "\n",
    "for i in range(len(blocks)):\n",
    "    blocks[i].set_index(blocks[i].index.droplevel(\"model\"))\n",
    "    blocks[i] = blocks[i].reset_index()\n",
    "    blocks[i].drop(\"model\", axis=1, inplace=True)\n",
    "    if i == 0:\n",
    "        metric_col = blocks[i][\"metric\"]\n",
    "    blocks[i].drop(\"metric\", axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.concat([metric_col] + blocks, axis=1, keys=[\"\"]+model_names)\n",
    "df2.set_index(df2.columns[0],inplace=True)\n",
    "df2.index.names = [\"Metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                        LogReg                    LogReg (debiased)            \\\n                         total  pos   neg p-value             total  pos  neg   \nMetric                                                                          \nEqual Opportunity        0.083   1%   99%    0.04             0.048  93%   7%   \nPredictive Equality      0.092   0%  100%    0.09             0.025  62%  38%   \nCalibration              0.291  46%   54%    0.35             0.299  58%  42%   \nROC bias                 0.044  98%    2%    0.80             0.050  98%   2%   \nxROC bias                0.133   0%  100%    0.02             0.057  93%   7%   \nEqual Opportunity (U)    0.041   3%   97%    0.13             0.036  97%   3%   \nPredictive Equality (U)  0.078   1%   99%    0.10             0.024  74%  26%   \nCalibration (U)          0.246  40%   60%    0.57             0.225  75%  25%   \n\n                                 \n                        p-value  \nMetric                           \nEqual Opportunity          0.32  \nPredictive Equality        0.99  \nCalibration                0.26  \nROC bias                   0.69  \nxROC bias                  0.54  \nEqual Opportunity (U)      0.23  \nPredictive Equality (U)    0.98  \nCalibration (U)            0.84  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">LogReg</th>\n      <th colspan=\"4\" halign=\"left\">LogReg (debiased)</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>total</th>\n      <th>pos</th>\n      <th>neg</th>\n      <th>p-value</th>\n      <th>total</th>\n      <th>pos</th>\n      <th>neg</th>\n      <th>p-value</th>\n    </tr>\n    <tr>\n      <th>Metric</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Equal Opportunity</th>\n      <td>0.083</td>\n      <td>1%</td>\n      <td>99%</td>\n      <td>0.04</td>\n      <td>0.048</td>\n      <td>93%</td>\n      <td>7%</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>Predictive Equality</th>\n      <td>0.092</td>\n      <td>0%</td>\n      <td>100%</td>\n      <td>0.09</td>\n      <td>0.025</td>\n      <td>62%</td>\n      <td>38%</td>\n      <td>0.99</td>\n    </tr>\n    <tr>\n      <th>Calibration</th>\n      <td>0.291</td>\n      <td>46%</td>\n      <td>54%</td>\n      <td>0.35</td>\n      <td>0.299</td>\n      <td>58%</td>\n      <td>42%</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>ROC bias</th>\n      <td>0.044</td>\n      <td>98%</td>\n      <td>2%</td>\n      <td>0.80</td>\n      <td>0.050</td>\n      <td>98%</td>\n      <td>2%</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>xROC bias</th>\n      <td>0.133</td>\n      <td>0%</td>\n      <td>100%</td>\n      <td>0.02</td>\n      <td>0.057</td>\n      <td>93%</td>\n      <td>7%</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>Equal Opportunity (U)</th>\n      <td>0.041</td>\n      <td>3%</td>\n      <td>97%</td>\n      <td>0.13</td>\n      <td>0.036</td>\n      <td>97%</td>\n      <td>3%</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>Predictive Equality (U)</th>\n      <td>0.078</td>\n      <td>1%</td>\n      <td>99%</td>\n      <td>0.10</td>\n      <td>0.024</td>\n      <td>74%</td>\n      <td>26%</td>\n      <td>0.98</td>\n    </tr>\n    <tr>\n      <th>Calibration (U)</th>\n      <td>0.246</td>\n      <td>40%</td>\n      <td>60%</td>\n      <td>0.57</td>\n      <td>0.225</td>\n      <td>75%</td>\n      <td>25%</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
